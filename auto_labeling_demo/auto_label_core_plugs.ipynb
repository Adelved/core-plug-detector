{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "source": [
    "## Lisence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Modifications copyright 2020 Dennis Adelved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "import re\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "#if StrictVersion(tf.__version__) < StrictVersion('1.12.0'):\n",
    "  #raise ImportError('Please upgrade your TensorFlow installation to v1.12.*.')\n",
    "\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the path to the folder containing the exported inference graph\n",
    "MODEL_NAME = 'graph_plugs_fine_tune'\n",
    "\n",
    "#adding the frozen inference graph to the path\n",
    "PATH_TO_FROZEN_GRAPH = os.path.join(MODEL_NAME,'frozen_inference_graph.pb')\n",
    "\n",
    "#Path to the label map\n",
    "PATH_TO_LABELS = 'labelmap_plugs.pbtxt'\n",
    "\n",
    "#Path to the images that are used for inference. Here only three sample images are given.\n",
    "#However, more can be added to this directory\n",
    "PATH_TO_TEST_IMAGES_DIR = 'images'\n",
    "\n",
    "#The output directory for the cropped core images. If no cropping is desired set OUTPUT_DIR = None\n",
    "OUTPUT_DIR = os.path.join('autolabel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBcB9QHLWKMU"
   },
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KezjCRVvWKMV"
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hDbpHkiWWKMX"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'label_map_util' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-d9bd1cb2606d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcategory_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_map_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_category_index_from_labelmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPATH_TO_LABELS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_display_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'label_map_util' is not defined"
     ]
    }
   ],
   "source": [
    "'''category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aSlYc3JkWKMa"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_1AGhrWKMc"
   },
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run inference on image using the frozen inference graph\n",
    "def run_inference_for_single_image(image, graph):\n",
    "\n",
    "\n",
    "    if 'detection_masks' in tensor_dict:\n",
    "        # The following processing is only for single image\n",
    "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
    "        detection_masks_reframed = tf.cast(\n",
    "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "        # Follow the convention by adding back the batch dimension\n",
    "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "            detection_masks_reframed, 0)\n",
    "\n",
    "\n",
    "    image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "    # Run inference\n",
    "    output_dict = sess.run(tensor_dict,\n",
    "                         feed_dict={image_tensor: image})\n",
    "\n",
    "    # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "    output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "    output_dict['detection_classes'] = output_dict[\n",
    "      'detection_classes'][0].astype(np.int64)\n",
    "    output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "    output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "    if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3a5wMHN8WKMh"
   },
   "outputs": [],
   "source": [
    "#Generate list of image paths expected input : RGB image with dimensions [height,width,depth]\n",
    "\n",
    "\n",
    "\n",
    "TEST_IMAGE_PATHS = []\n",
    "for im in os.listdir(PATH_TO_TEST_IMAGES_DIR):\n",
    "    if '.jpg' in im:\n",
    "        TEST_IMAGE_PATHS.append(os.path.join(PATH_TO_TEST_IMAGES_DIR + '/' +  im))\n",
    "\n",
    "#empty list for saving the output dicts for each prediction\n",
    "dicts = []\n",
    "IMAGE_SIZE = (20,20)\n",
    "#Retrieve the detection data from the inference\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "      # Get handles to input and output tensors\n",
    "        ops = tf.get_default_graph().get_operations()\n",
    "        for op in ops: \n",
    "            op._set_device('/device:CPU:*')\n",
    "        all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "        tensor_dict = {}\n",
    "        for key in [\n",
    "          'num_detections', 'detection_boxes', 'detection_scores',\n",
    "          'detection_classes', 'detection_masks'\n",
    "      ]:\n",
    "            tensor_name = key + ':0'\n",
    "            if tensor_name in all_tensor_names:\n",
    "                tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "              tensor_name)\n",
    "\n",
    "        for image_path in TEST_IMAGE_PATHS:\n",
    "            \n",
    "            #Convert RGB image to grayscale\n",
    "            image = Image.open(image_path).convert('L')\n",
    "\n",
    "            img = np.asarray(image)\n",
    "            new_im = np.ndarray((img.shape[0],img.shape[1],3))\n",
    "            for d in range(new_im.shape[-1]):\n",
    "                new_im[:,:,d] = img[:,:]\n",
    "                \n",
    "            image_np = np.copy(new_im)\n",
    "\n",
    "\n",
    "\n",
    "            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "\n",
    "            # Actual detection.\n",
    "            output_dict = run_inference_for_single_image(image_np_expanded, detection_graph)  \n",
    "            \n",
    "            #append detection from image to the detection list\n",
    "            dicts.append(output_dict)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sorted_boxes(denrom,classes,sortby=0):\n",
    "    concat = np.hstack((denorm,classes)).astype(int)\n",
    "    sort_val = np.zeros_like(concat)\n",
    "    sortind = np.argsort(denorm[:,0].argsort())\n",
    "    for i in range(sortind.shape[0]):\n",
    "        row = np.argwhere(sortind == i)\n",
    "        sort_val[i,:] = concat[row,:]\n",
    "    return sort_val\n",
    "\n",
    "def pixel_to_depth(top,base,pixel_height):\n",
    "    return (base-top) / pixel_height\n",
    "\n",
    "def plug_to_depth(impath,boxes):\n",
    "    im = np.asarray(Image.open(impath))\n",
    "    top,base = float(impath.split('.')[0].split('_')[-2]), float(impath.split('.')[0].split('_')[-1])\n",
    "    meter_per_pixel = pixel_to_depth(top,base,im.shape[0])\n",
    "    mid_diff = ((boxes[:,2] - boxes[:,0]) / 2)\n",
    "    mid = mid_diff + boxes[:,0]\n",
    "    names = []\n",
    "    depth = []\n",
    "    pix = []\n",
    "    image = []\n",
    "    for i in range(len(mid)):\n",
    "\n",
    "        names.append(class_to_name(boxes[i,-1]))\n",
    "        depth.append(mid[i] * meter_per_pixel + top)\n",
    "        pix.append(mid[i])\n",
    "        image.append(impath)\n",
    "        \n",
    "    d = {'PlugType': names, 'Depth' : depth,'Pixel Location' : pix,'Source':image}\n",
    "    df = pd.DataFrame(d)\n",
    "    return df\n",
    "\n",
    "\n",
    "#Denormalize the bounding box coordinates generated by the model\n",
    "def denormalize(array,image):\n",
    "    if array.ndim ==1:\n",
    "        array = array[None,:]\n",
    "    print(array.shape)\n",
    "    denorm = np.zeros_like(array)\n",
    "    h,w = image.shape[0:2]\n",
    "    denorm[:,0] = array[:,0] * h\n",
    "    denorm[:,1] = array[:,1] * w\n",
    "    denorm[:,2] = array[:,2] * h\n",
    "    denorm[:,3] = array[:,3] * w\n",
    "    return denorm\n",
    "\n",
    "#non-max supression function (remove overlaping bounding boxes)\n",
    "def non_max_supression(boxes,overlapThresh):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "    \n",
    "    pick = []\n",
    "    xmin = boxes[:,0]\n",
    "    ymin = boxes[:,1]\n",
    "    xmax = boxes[:,2]\n",
    "    ymax = boxes[:,3]\n",
    "    area = (xmax - xmin + 1) * (ymax - ymin + 1)\n",
    "    idxs = np.argsort(ymax)\n",
    "    \n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "        \n",
    "        xxmin = np.maximum(xmin[i], xmin[idxs[:last]])\n",
    "        yymin = np.maximum(ymin[i], ymin[idxs[:last]])\n",
    "        xxmax = np.minimum(xmax[i], xmax[idxs[:last]])\n",
    "        yymax = np.minimum(ymax[i], ymax[idxs[:last]])\n",
    "        \n",
    "        w = np.maximum(0, xxmax - xxmin + 1)\n",
    "        h = np.maximum(0, yymax - yymin + 1)\n",
    " \n",
    "\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "\n",
    "        idxs = np.delete(idxs, np.concatenate(([last],\n",
    "            np.where(overlap > overlapThresh)[0])))\n",
    " \n",
    "    return boxes[pick].astype(\"int\")\n",
    "    \n",
    "#returns the filename and file extension from the path\n",
    "def get_filename(path):\n",
    "    filename = re.findall('^(.+)/([^/]+)$',path)\n",
    "    filename = filename[0][1].split('.')\n",
    "    return filename\n",
    "\n",
    "\n",
    "def query_image_from_measurement(measurement_depth,dataframe,pad=80):\n",
    "    ind = (np.abs(dataframe['Depth'].values - measurement_depth)).argmin()\n",
    "    center = dataframe['Pixel Location'].iloc[ind]\n",
    "    testim = np.asarray(Image.open(dataframe['Source'][ind]))\n",
    "    crop = testim[int(center)-pad:int(center)+pad]\n",
    "    return crop\n",
    "\n",
    "\n",
    "\n",
    "def name_from_path(image_path):\n",
    "    name_components = image_path.split('/')[-1].split('_')[0:3]\n",
    "    name = name_components[0] + '_' + name_components[1] + '-' + name_components[2]\n",
    "    top = (image_path.split('_')[-2])\n",
    "    base = (image_path.split('_')[-1].split('.jpg')[0])\n",
    "    return name,float(top),float(base)\n",
    "\n",
    "def get_well(image_path,df):\n",
    "    name,top,base = name_from_path(image_path)\n",
    "    current_well = df[df['Well Name'] == name]\n",
    "    g_top =  current_well[current_well['Measured Depth'] >= top]\n",
    "    data = g_top[g_top['Measured Depth'] <= base]\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "def depth_conversion(df,plugtype):\n",
    "    df = df[df['PlugType'] == plugtype].values\n",
    "    pixel_diff = np.diff(df[:,2])\n",
    "    depth_diff = np.diff(df[:,1])\n",
    "    return depth_diff/pixel_diff\n",
    "\n",
    "\n",
    "\n",
    "def get_well_log_demo():    \n",
    "    wellpath = glob.glob(os.path.join('wellog','*'))\n",
    "    data = []\n",
    "    header = []\n",
    "    head_ind = 0\n",
    "    val_ind = 0\n",
    "    with open(wellpath[0]) as f:\n",
    "        for ind,line in enumerate(f):\n",
    "            data.append(line)\n",
    "            if '~Curves' in line:\n",
    "                head_ind = ind + 1\n",
    "            if '~Ascii' in line:\n",
    "                val_ind = ind + 1\n",
    "    data = [e.split() for e in data[val_ind:]]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def class_to_name(c):\n",
    "    if c == 1:\n",
    "        name = 'hplug'\n",
    "        return name\n",
    "    if c == 2:\n",
    "        name = 'vplug'\n",
    "        return name\n",
    "    if c == 3: \n",
    "        name = 'scal'\n",
    "        return name\n",
    "    else:\n",
    "        return 'Non-defined class'\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def match_objects(in_xml,in_prediction):\n",
    "    counter = 0\n",
    "    new = []\n",
    "    while counter < len(in_prediction):\n",
    "        temp = copy.deepcopy(in_xml[0])\n",
    "        new.append(temp)\n",
    "        counter += 1\n",
    "    return new\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def auto_annotate_xml(im_path,xml_template_path,predicted_bounding_boxes):\n",
    "    \n",
    "    output_path = os.path.join(os.getcwd(),'autolabel')\n",
    "    new_xml_path = im_path.split('/')[-1].split('.')[0] + '.xml'\n",
    "    xml_copy_path = shutil.copy(xml_template_path, os.path.join(output_path, new_xml_path))\n",
    "    print(xml_copy_path)\n",
    "    \n",
    "    tree = ET.parse(xml_copy_path)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "   \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    im = Image.open(im_path)\n",
    "    im = np.asarray(im)\n",
    "    h,w = im.shape\n",
    "    d = 1\n",
    "    root.find('folder').text = output_path.split('/')[-1]\n",
    "    root.find('filename').text = im_path.split('/')[-1]\n",
    "    root.find('path').text = os.path.join(output_path,im_path.split('/')[-1])\n",
    "    root.find('size').find('width').text = str(w)\n",
    "    root.find('size').find('height').text = str(h)\n",
    "    root.find('size').find('depth').text = str(d)\n",
    "    \n",
    "    new_objects = match_objects(root.findall('object'),predicted_bounding_boxes)\n",
    "    \n",
    "    \n",
    "    for obj in root.findall('object'):\n",
    "        root.remove(obj)\n",
    "    #print(len(root.findall('object')))\n",
    "    \n",
    "    \n",
    "        \n",
    "    for new_obj in new_objects:\n",
    "        root.append(new_obj)\n",
    "    #print(len(root.findall('object')))\n",
    "        \n",
    "    #print(len(root.findall('object')))\n",
    "    #print(len(denorm))\n",
    "    for ind,obj in enumerate(root.findall('object')):\n",
    "\n",
    "        obj.find('name').text = class_to_name(predicted_bounding_boxes[ind,-1])\n",
    "        obj.find('bndbox').find('ymin').text = str((predicted_bounding_boxes[ind,0]))\n",
    "        obj.find('bndbox').find('xmin').text = str((predicted_bounding_boxes[ind,1]))\n",
    "        obj.find('bndbox').find('ymax').text =str( (predicted_bounding_boxes[ind,2]))\n",
    "        obj.find('bndbox').find('xmax').text = str((predicted_bounding_boxes[ind,3]))\n",
    "\n",
    "    \n",
    "    \n",
    "    shutil.copy(im_path,os.path.join(output_path,im_path.split('/')[-1]))\n",
    "    tree.write(xml_copy_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 4)\n",
      "/home/dennis/anaconda3/envs/gputest/models/research/object_detection_latest_gpu/Use_case/autolabel/autolabel/6407_1_3_3755_3756.xml\n",
      "(3, 4)\n",
      "/home/dennis/anaconda3/envs/gputest/models/research/object_detection_latest_gpu/Use_case/autolabel/autolabel/6407_1_3_3757_3758.xml\n",
      "(3, 4)\n",
      "/home/dennis/anaconda3/envs/gputest/models/research/object_detection_latest_gpu/Use_case/autolabel/autolabel/6407_1_3_3753_3754.xml\n",
      "(3, 4)\n",
      "/home/dennis/anaconda3/envs/gputest/models/research/object_detection_latest_gpu/Use_case/autolabel/autolabel/6407_1_3_3752_3753.xml\n",
      "(3, 4)\n",
      "/home/dennis/anaconda3/envs/gputest/models/research/object_detection_latest_gpu/Use_case/autolabel/autolabel/6407_1_3_3751_3752.xml\n",
      "(3, 4)\n",
      "/home/dennis/anaconda3/envs/gputest/models/research/object_detection_latest_gpu/Use_case/autolabel/autolabel/6407_1_3_3716_3717.xml\n",
      "(3, 4)\n",
      "/home/dennis/anaconda3/envs/gputest/models/research/object_detection_latest_gpu/Use_case/autolabel/autolabel/6407_1_3_3750_3751.xml\n",
      "(3, 4)\n",
      "/home/dennis/anaconda3/envs/gputest/models/research/object_detection_latest_gpu/Use_case/autolabel/autolabel/6407_1_3_3748_3749.xml\n",
      "(3, 4)\n",
      "/home/dennis/anaconda3/envs/gputest/models/research/object_detection_latest_gpu/Use_case/autolabel/autolabel/6407_1_3_3756_3757.xml\n",
      "(3, 4)\n",
      "/home/dennis/anaconda3/envs/gputest/models/research/object_detection_latest_gpu/Use_case/autolabel/autolabel/6407_1_3_3749_3750.xml\n",
      "(3, 4)\n",
      "/home/dennis/anaconda3/envs/gputest/models/research/object_detection_latest_gpu/Use_case/autolabel/autolabel/6407_1_3_3754_3755.xml\n"
     ]
    }
   ],
   "source": [
    "#Make xml files from predictions and export to output directory\n",
    "for ind,d in enumerate(dicts):\n",
    "    s= np.argwhere(d['detection_scores'] > 0.5)\n",
    "    boxes = np.squeeze(d['detection_boxes'][s])\n",
    "    classes = d['detection_classes'][s]\n",
    "    image_np = Image.open(TEST_IMAGE_PATHS[ind])\n",
    "    image_np = np.asarray(image_np)\n",
    "    denorm = denormalize(boxes,image_np)\n",
    "    denorm = sorted_boxes(denorm,classes)\n",
    "    \n",
    "    \n",
    "    auto_annotate_xml(TEST_IMAGE_PATHS[ind],'template.xml',denorm)\n",
    "    \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "object_detection_tutorial.ipynb?workspaceId=ronnyvotel:python_inference::citc",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
