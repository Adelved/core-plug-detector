{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "source": [
    "## Lisence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Modifications copyright 2020 Dennis Adelved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# =============================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import xml.etree.ElementTree as ET\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "import re\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "#if StrictVersion(tf.__version__) < StrictVersion('1.12.0'):\n",
    "  #raise ImportError('Please upgrade your TensorFlow installation to v1.12.*.')\n",
    "\n",
    "\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import label_map_util\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the path to the folder containing the exported inference graph\n",
    "MODEL_NAME = 'inference-graph-demo'\n",
    "\n",
    "#adding the frozen inference graph to the path\n",
    "PATH_TO_FROZEN_GRAPH = os.path.join(MODEL_NAME,'frozen_inference_graph.pb')\n",
    "\n",
    "#Path to the label map\n",
    "PATH_TO_LABELS = 'labelmap_plugs.pbtxt'\n",
    "\n",
    "#Path to the images that are used for inference.\n",
    "PATH_TO_TEST_IMAGES_DIR = 'images'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBcB9QHLWKMU"
   },
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KezjCRVvWKMV"
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hDbpHkiWWKMX"
   },
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aSlYc3JkWKMa"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "      (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_1AGhrWKMc"
   },
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run inference on image using the frozen inference graph\n",
    "def run_inference_for_single_image(image, graph):\n",
    "\n",
    "\n",
    "    if 'detection_masks' in tensor_dict:\n",
    "        # The following processing is only for single image\n",
    "        detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "        detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "        # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "        real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "        detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "        detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "        detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "            detection_masks, detection_boxes, image.shape[1], image.shape[2])\n",
    "        detection_masks_reframed = tf.cast(\n",
    "            tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "        # Follow the convention by adding back the batch dimension\n",
    "        tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "            detection_masks_reframed, 0)\n",
    "\n",
    "\n",
    "    image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "    # Run inference\n",
    "    output_dict = sess.run(tensor_dict,\n",
    "                         feed_dict={image_tensor: image})\n",
    "\n",
    "    # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "    output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "    output_dict['detection_classes'] = output_dict[\n",
    "      'detection_classes'][0].astype(np.int64)\n",
    "    output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "    output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "    if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3a5wMHN8WKMh"
   },
   "outputs": [],
   "source": [
    "#Generate list of image paths\n",
    "TEST_IMAGE_PATHS = []\n",
    "for im in os.listdir(PATH_TO_TEST_IMAGES_DIR):\n",
    "    if '.jpg' in im:\n",
    "        TEST_IMAGE_PATHS.append(os.path.join(PATH_TO_TEST_IMAGES_DIR + '/' +  im))\n",
    "        \n",
    "#SET IMAGE SIZE\n",
    "IMAGE_SIZE = (20,20)\n",
    "\n",
    "#SET TRUE IF THE PREDICTED BOUNDING BOXES SHALL BE VISUALIZED ON THE INPUT IMAGE\n",
    "VISUALIZE = False\n",
    "        \n",
    "#empty list for saving the output dicts for each prediction\n",
    "dicts = []\n",
    "\n",
    "image_dims = []\n",
    "\n",
    "\n",
    "#Retrieve the detection data from the inference\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "      # Get handles to input and output tensors\n",
    "        ops = tf.get_default_graph().get_operations()\n",
    "        for op in ops: \n",
    "            op._set_device('/device:CPU:*')\n",
    "        all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "        tensor_dict = {}\n",
    "        for key in [\n",
    "          'num_detections', 'detection_boxes', 'detection_scores',\n",
    "          'detection_classes', 'detection_masks'\n",
    "      ]:\n",
    "            tensor_name = key + ':0'\n",
    "            if tensor_name in all_tensor_names:\n",
    "                tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "              tensor_name)\n",
    "\n",
    "        for image_path in TEST_IMAGE_PATHS:\n",
    "\n",
    "            #Convert RGB image to grayscale\n",
    "            img = np.array(Image.open(image_path).convert('L'))\n",
    "            \n",
    "            #Expand the number of channels to 3, i.e. expand the grayscale channel.\n",
    "            new_im = np.ndarray((img.shape[0],img.shape[1],3))\n",
    "            for d in range(new_im.shape[-1]):\n",
    "                new_im[:,:,d] = img[:,:]\n",
    "            \n",
    "            image_dims.append((new_im.shape[0],new_im.shape[1]))\n",
    "            \n",
    "            #Predict bounding boxes on grayscale image. \n",
    "            output_dict = run_inference_for_single_image(new_im[None,:,:,:], detection_graph)  \n",
    "            \n",
    "            \n",
    "            #append detection from image to the detection list\n",
    "            dicts.append(output_dict)\n",
    "            \n",
    "            \n",
    "            \n",
    "            #Visualize detected bounding boxes on RGB image\n",
    "            visualize_image = np.array(Image.open(image_path))\n",
    "            \n",
    "            if VISUALIZE == True:\n",
    "                vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "                  visualize_image,\n",
    "                  output_dict['detection_boxes'],\n",
    "                  output_dict['detection_classes'],\n",
    "                  output_dict['detection_scores'],\n",
    "                  category_index,\n",
    "                  instance_masks=output_dict.get('detection_masks'),\n",
    "                  use_normalized_coordinates=True,\n",
    "                  line_thickness=4)\n",
    "                plt.figure(figsize=IMAGE_SIZE)\n",
    "                plt.imshow(visualize_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sorted_boxes(denrom,classes,sortby=0):\n",
    "    concat = np.hstack((denorm,classes)).astype(int)\n",
    "    sort_val = np.zeros_like(concat)\n",
    "    sortind = np.argsort(denorm[:,0].argsort())\n",
    "    for i in range(sortind.shape[0]):\n",
    "        row = np.argwhere(sortind == i)\n",
    "        sort_val[i,:] = concat[row,:]\n",
    "    return sort_val\n",
    "\n",
    "def pixel_to_depth(top,base,pixel_height):\n",
    "    return (base-top) / pixel_height\n",
    "\n",
    "def plug_to_depth(impath,boxes):\n",
    "    im = np.asarray(Image.open(impath))\n",
    "    \n",
    "    top_str,base_str =impath.split('.')[0].split('_')[-2], (impath.split('.')[0].split('_')[-1])\n",
    "    \n",
    "    if ',' in top_str:\n",
    "        top_str = top_str.split(',')[0] + '.' + top_str.split(',')[-1]\n",
    "\n",
    "    if ',' in base_str:\n",
    "        base_str = base_str.split(',')[0] + '.' + base_str.split(',')[-1]\n",
    "\n",
    "    \n",
    "    top,base = float(top_str), float(base_str)\n",
    "    meter_per_pixel = pixel_to_depth(top,base,im.shape[0])\n",
    "    mid_diff = ((boxes[:,2] - boxes[:,0]) / 2)\n",
    "    mid = mid_diff + boxes[:,0]\n",
    "    names = []\n",
    "    depth = []\n",
    "    pix = []\n",
    "    image = []\n",
    "    for i in range(len(mid)):\n",
    "\n",
    "        names.append(class_to_name(boxes[i,-1]))\n",
    "        depth.append(mid[i] * meter_per_pixel + top)\n",
    "        pix.append(mid[i])\n",
    "        image.append(impath)\n",
    "        \n",
    "\n",
    "    return names,depth,pix,image\n",
    "\n",
    "\n",
    "#Denormalize the bounding box coordinates generated by the model\n",
    "def denormalize(array,image_dims):\n",
    "    if array.ndim==1:\n",
    "        array=array[None,:]\n",
    "    denorm = np.zeros_like(array)\n",
    "    h,w = image_dims\n",
    "\n",
    "    \n",
    "\n",
    "    denorm[:,0] = array[:,0] * h\n",
    "    denorm[:,1] = array[:,1] * w\n",
    "    denorm[:,2] = array[:,2] * h\n",
    "    denorm[:,3] = array[:,3] * w\n",
    "    return denorm\n",
    "\n",
    "    \n",
    "#returns the filename and file extension from the path\n",
    "def get_filename(path):\n",
    "    filename = re.findall('^(.+)/([^/]+)$',path)\n",
    "    filename = filename[0][1].split('.')\n",
    "    return filenametop\n",
    "\n",
    "\n",
    "def name_from_path(image_path):\n",
    "    name_components = image_path.split('/')[-1].split('_')[0:3]\n",
    "    name = name_components[0] + '_' + name_components[1] + '-' + name_components[2]\n",
    "    top = (image_path.split('_')[-2])\n",
    "    base = (image_path.split('_')[-1].split('.jpg')[0])\n",
    "    return name,float(top),float(base)\n",
    "\n",
    "def get_well(image_path,df):\n",
    "    name,top,base = name_from_path(image_path)\n",
    "    current_well = df[df['Well Name'] == name]\n",
    "    g_top =  current_well[current_well['Measured Depth'] >= top]\n",
    "    data = g_top[g_top['Measured Depth'] <= base]\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "def class_to_name(c):\n",
    "    if c == 1:\n",
    "        name = 'hplug'\n",
    "        return name\n",
    "    if c == 2:\n",
    "        name = 'vplug'\n",
    "        return name\n",
    "    if c == 3: \n",
    "        name = 'scal'\n",
    "        return name\n",
    "    else:\n",
    "        return 'Non-defined class'\n",
    "    \n",
    "    \n",
    "\n",
    "def depth_conversion(df,plugtype):\n",
    "    df = df[df['PlugType'] == plugtype].values\n",
    "    pixel_diff = np.diff(df[:,2])\n",
    "    depth_diff = np.diff(df[:,1])\n",
    "    return depth_diff/pixel_diff\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Pixel-Depth mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Plug Type</th>\n",
       "      <th>Depth</th>\n",
       "      <th>Pixel Location</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3632.026906</td>\n",
       "      <td>66.0</td>\n",
       "      <td>images/6407_1_3_3632_3633.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3632.052385</td>\n",
       "      <td>128.5</td>\n",
       "      <td>images/6407_1_3_3632_3633.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3632.324093</td>\n",
       "      <td>795.0</td>\n",
       "      <td>images/6407_1_3_3632_3633.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3632.328577</td>\n",
       "      <td>806.0</td>\n",
       "      <td>images/6407_1_3_3632_3633.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3632.757440</td>\n",
       "      <td>1858.0</td>\n",
       "      <td>images/6407_1_3_3632_3633.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3632.798410</td>\n",
       "      <td>1958.5</td>\n",
       "      <td>images/6407_1_3_3632_3633.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3632.917652</td>\n",
       "      <td>2251.0</td>\n",
       "      <td>images/6407_1_3_3632_3633.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3632.974725</td>\n",
       "      <td>2391.0</td>\n",
       "      <td>images/6407_1_3_3632_3633.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3634.041971</td>\n",
       "      <td>103.5</td>\n",
       "      <td>images/6407_1_3_3634_3635.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>scal</td>\n",
       "      <td>3634.061841</td>\n",
       "      <td>152.5</td>\n",
       "      <td>images/6407_1_3_3634_3635.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3634.289943</td>\n",
       "      <td>715.0</td>\n",
       "      <td>images/6407_1_3_3634_3635.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>scal</td>\n",
       "      <td>3634.358881</td>\n",
       "      <td>885.0</td>\n",
       "      <td>images/6407_1_3_3634_3635.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3634.661800</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>images/6407_1_3_3634_3635.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3634.715937</td>\n",
       "      <td>1765.5</td>\n",
       "      <td>images/6407_1_3_3634_3635.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>scal</td>\n",
       "      <td>3634.915856</td>\n",
       "      <td>2258.5</td>\n",
       "      <td>images/6407_1_3_3634_3635.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3638.021937</td>\n",
       "      <td>53.0</td>\n",
       "      <td>images/6407_1_3_3638_3639.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>scal</td>\n",
       "      <td>3639.065979</td>\n",
       "      <td>160.0</td>\n",
       "      <td>images/6407_1_3_3639_3640.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>scal</td>\n",
       "      <td>3639.149691</td>\n",
       "      <td>363.0</td>\n",
       "      <td>images/6407_1_3_3639_3640.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>scal</td>\n",
       "      <td>3639.361237</td>\n",
       "      <td>876.0</td>\n",
       "      <td>images/6407_1_3_3639_3640.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>scal</td>\n",
       "      <td>3639.709278</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>images/6407_1_3_3639_3640.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3639.770515</td>\n",
       "      <td>1868.5</td>\n",
       "      <td>images/6407_1_3_3639_3640.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3643.031121</td>\n",
       "      <td>75.5</td>\n",
       "      <td>images/6407_1_3_3643_3644.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>scal</td>\n",
       "      <td>3643.104493</td>\n",
       "      <td>253.5</td>\n",
       "      <td>images/6407_1_3_3643_3644.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3643.279266</td>\n",
       "      <td>677.5</td>\n",
       "      <td>images/6407_1_3_3643_3644.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3643.334295</td>\n",
       "      <td>811.0</td>\n",
       "      <td>images/6407_1_3_3643_3644.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3643.654163</td>\n",
       "      <td>1587.0</td>\n",
       "      <td>images/6407_1_3_3643_3644.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3643.674979</td>\n",
       "      <td>1637.5</td>\n",
       "      <td>images/6407_1_3_3643_3644.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>scal</td>\n",
       "      <td>3643.945177</td>\n",
       "      <td>2293.0</td>\n",
       "      <td>images/6407_1_3_3643_3644.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3643.956925</td>\n",
       "      <td>2321.5</td>\n",
       "      <td>images/6407_1_3_3643_3644.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3648.027032</td>\n",
       "      <td>67.5</td>\n",
       "      <td>images/6407_1_3_3648_3649.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3968.019002</td>\n",
       "      <td>41.5</td>\n",
       "      <td>images/6406_3_3_3968_3969.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>scal</td>\n",
       "      <td>3968.084249</td>\n",
       "      <td>184.0</td>\n",
       "      <td>images/6406_3_3_3968_3969.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>scal</td>\n",
       "      <td>3968.129579</td>\n",
       "      <td>283.0</td>\n",
       "      <td>images/6406_3_3_3968_3969.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3968.256410</td>\n",
       "      <td>560.0</td>\n",
       "      <td>images/6406_3_3_3968_3969.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3968.478709</td>\n",
       "      <td>1045.5</td>\n",
       "      <td>images/6406_3_3_3968_3969.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3968.513278</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>images/6406_3_3_3968_3969.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3968.697115</td>\n",
       "      <td>1522.5</td>\n",
       "      <td>images/6406_3_3_3968_3969.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3969.043623</td>\n",
       "      <td>98.5</td>\n",
       "      <td>images/6406_3_3_3969_3970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3969.067316</td>\n",
       "      <td>152.0</td>\n",
       "      <td>images/6406_3_3_3969_3970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>scal</td>\n",
       "      <td>3969.183570</td>\n",
       "      <td>414.5</td>\n",
       "      <td>images/6406_3_3_3969_3970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3969.267715</td>\n",
       "      <td>604.5</td>\n",
       "      <td>images/6406_3_3_3969_3970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3969.268379</td>\n",
       "      <td>606.0</td>\n",
       "      <td>images/6406_3_3_3969_3970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3969.281001</td>\n",
       "      <td>634.5</td>\n",
       "      <td>images/6406_3_3_3969_3970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>scal</td>\n",
       "      <td>3969.528787</td>\n",
       "      <td>1194.0</td>\n",
       "      <td>images/6406_3_3_3969_3970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3969.767715</td>\n",
       "      <td>1733.5</td>\n",
       "      <td>images/6406_3_3_3969_3970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3969.771036</td>\n",
       "      <td>1741.0</td>\n",
       "      <td>images/6406_3_3_3969_3970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3969.859389</td>\n",
       "      <td>1940.5</td>\n",
       "      <td>images/6406_3_3_3969_3970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>scal</td>\n",
       "      <td>3969.859832</td>\n",
       "      <td>1941.5</td>\n",
       "      <td>images/6406_3_3_3969_3970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3969.922719</td>\n",
       "      <td>2083.5</td>\n",
       "      <td>images/6406_3_3_3969_3970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3969.969663</td>\n",
       "      <td>2189.5</td>\n",
       "      <td>images/6406_3_3_3969_3970.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3970.728138</td>\n",
       "      <td>1607.0</td>\n",
       "      <td>images/6406_3_3_3970_3971.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3971.048440</td>\n",
       "      <td>104.0</td>\n",
       "      <td>images/6406_3_3_3971_3972.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>scal</td>\n",
       "      <td>3971.107126</td>\n",
       "      <td>230.0</td>\n",
       "      <td>images/6406_3_3_3971_3972.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>scal</td>\n",
       "      <td>3971.153237</td>\n",
       "      <td>329.0</td>\n",
       "      <td>images/6406_3_3_3971_3972.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3971.218677</td>\n",
       "      <td>469.5</td>\n",
       "      <td>images/6406_3_3_3971_3972.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3971.449464</td>\n",
       "      <td>965.0</td>\n",
       "      <td>images/6406_3_3_3971_3972.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3971.486260</td>\n",
       "      <td>1044.0</td>\n",
       "      <td>images/6406_3_3_3971_3972.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3971.721938</td>\n",
       "      <td>1550.0</td>\n",
       "      <td>images/6406_3_3_3971_3972.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>vplug</td>\n",
       "      <td>3971.758034</td>\n",
       "      <td>1627.5</td>\n",
       "      <td>images/6406_3_3_3971_3972.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>hplug</td>\n",
       "      <td>3971.765720</td>\n",
       "      <td>1644.0</td>\n",
       "      <td>images/6406_3_3_3971_3972.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>269 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Plug Type        Depth  Pixel Location                         Source\n",
       "0       vplug  3632.026906            66.0  images/6407_1_3_3632_3633.jpg\n",
       "1       hplug  3632.052385           128.5  images/6407_1_3_3632_3633.jpg\n",
       "2       vplug  3632.324093           795.0  images/6407_1_3_3632_3633.jpg\n",
       "3       hplug  3632.328577           806.0  images/6407_1_3_3632_3633.jpg\n",
       "4       hplug  3632.757440          1858.0  images/6407_1_3_3632_3633.jpg\n",
       "5       vplug  3632.798410          1958.5  images/6407_1_3_3632_3633.jpg\n",
       "6       vplug  3632.917652          2251.0  images/6407_1_3_3632_3633.jpg\n",
       "7       hplug  3632.974725          2391.0  images/6407_1_3_3632_3633.jpg\n",
       "8       vplug  3634.041971           103.5  images/6407_1_3_3634_3635.jpg\n",
       "9        scal  3634.061841           152.5  images/6407_1_3_3634_3635.jpg\n",
       "10      vplug  3634.289943           715.0  images/6407_1_3_3634_3635.jpg\n",
       "11       scal  3634.358881           885.0  images/6407_1_3_3634_3635.jpg\n",
       "12      hplug  3634.661800          1632.0  images/6407_1_3_3634_3635.jpg\n",
       "13      vplug  3634.715937          1765.5  images/6407_1_3_3634_3635.jpg\n",
       "14       scal  3634.915856          2258.5  images/6407_1_3_3634_3635.jpg\n",
       "15      vplug  3638.021937            53.0  images/6407_1_3_3638_3639.jpg\n",
       "16       scal  3639.065979           160.0  images/6407_1_3_3639_3640.jpg\n",
       "17       scal  3639.149691           363.0  images/6407_1_3_3639_3640.jpg\n",
       "18       scal  3639.361237           876.0  images/6407_1_3_3639_3640.jpg\n",
       "19       scal  3639.709278          1720.0  images/6407_1_3_3639_3640.jpg\n",
       "20      vplug  3639.770515          1868.5  images/6407_1_3_3639_3640.jpg\n",
       "21      hplug  3643.031121            75.5  images/6407_1_3_3643_3644.jpg\n",
       "22       scal  3643.104493           253.5  images/6407_1_3_3643_3644.jpg\n",
       "23      vplug  3643.279266           677.5  images/6407_1_3_3643_3644.jpg\n",
       "24      hplug  3643.334295           811.0  images/6407_1_3_3643_3644.jpg\n",
       "25      hplug  3643.654163          1587.0  images/6407_1_3_3643_3644.jpg\n",
       "26      vplug  3643.674979          1637.5  images/6407_1_3_3643_3644.jpg\n",
       "27       scal  3643.945177          2293.0  images/6407_1_3_3643_3644.jpg\n",
       "28      vplug  3643.956925          2321.5  images/6407_1_3_3643_3644.jpg\n",
       "29      hplug  3648.027032            67.5  images/6407_1_3_3648_3649.jpg\n",
       "..        ...          ...             ...                            ...\n",
       "239     hplug  3968.019002            41.5  images/6406_3_3_3968_3969.jpg\n",
       "240      scal  3968.084249           184.0  images/6406_3_3_3968_3969.jpg\n",
       "241      scal  3968.129579           283.0  images/6406_3_3_3968_3969.jpg\n",
       "242     hplug  3968.256410           560.0  images/6406_3_3_3968_3969.jpg\n",
       "243     hplug  3968.478709          1045.5  images/6406_3_3_3968_3969.jpg\n",
       "244     vplug  3968.513278          1121.0  images/6406_3_3_3968_3969.jpg\n",
       "245     hplug  3968.697115          1522.5  images/6406_3_3_3968_3969.jpg\n",
       "246     hplug  3969.043623            98.5  images/6406_3_3_3969_3970.jpg\n",
       "247     vplug  3969.067316           152.0  images/6406_3_3_3969_3970.jpg\n",
       "248      scal  3969.183570           414.5  images/6406_3_3_3969_3970.jpg\n",
       "249     hplug  3969.267715           604.5  images/6406_3_3_3969_3970.jpg\n",
       "250     hplug  3969.268379           606.0  images/6406_3_3_3969_3970.jpg\n",
       "251     vplug  3969.281001           634.5  images/6406_3_3_3969_3970.jpg\n",
       "252      scal  3969.528787          1194.0  images/6406_3_3_3969_3970.jpg\n",
       "253     vplug  3969.767715          1733.5  images/6406_3_3_3969_3970.jpg\n",
       "254     hplug  3969.771036          1741.0  images/6406_3_3_3969_3970.jpg\n",
       "255     hplug  3969.859389          1940.5  images/6406_3_3_3969_3970.jpg\n",
       "256      scal  3969.859832          1941.5  images/6406_3_3_3969_3970.jpg\n",
       "257     vplug  3969.922719          2083.5  images/6406_3_3_3969_3970.jpg\n",
       "258     hplug  3969.969663          2189.5  images/6406_3_3_3969_3970.jpg\n",
       "259     hplug  3970.728138          1607.0  images/6406_3_3_3970_3971.jpg\n",
       "260     vplug  3971.048440           104.0  images/6406_3_3_3971_3972.jpg\n",
       "261      scal  3971.107126           230.0  images/6406_3_3_3971_3972.jpg\n",
       "262      scal  3971.153237           329.0  images/6406_3_3_3971_3972.jpg\n",
       "263     hplug  3971.218677           469.5  images/6406_3_3_3971_3972.jpg\n",
       "264     vplug  3971.449464           965.0  images/6406_3_3_3971_3972.jpg\n",
       "265     hplug  3971.486260          1044.0  images/6406_3_3_3971_3972.jpg\n",
       "266     vplug  3971.721938          1550.0  images/6406_3_3_3971_3972.jpg\n",
       "267     vplug  3971.758034          1627.5  images/6406_3_3_3971_3972.jpg\n",
       "268     hplug  3971.765720          1644.0  images/6406_3_3_3971_3972.jpg\n",
       "\n",
       "[269 rows x 4 columns]"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lnames=[]\n",
    "ldepth=[]\n",
    "lpix=[]\n",
    "limage=[]\n",
    "for ind,d in enumerate(dicts):\n",
    "    scores=np.argwhere(d['detection_scores'] > 0.5) \n",
    "    boxes = np.squeeze(d['detection_boxes'][scores]) \n",
    "    classes = d['detection_classes'][scores]\n",
    "    denorm = denormalize(boxes,image_dims[ind]) \n",
    "    denorm = sorted_boxes(denorm,classes) \n",
    "    names,depth,pix,image = plug_to_depth(TEST_IMAGE_PATHS[ind],denorm)\n",
    "    lnames += names\n",
    "    ldepth += depth\n",
    "    lpix += pix\n",
    "    limage += image\n",
    "\n",
    "\n",
    "d = {'Plug Type': lnames, 'Depth': ldepth, 'Pixel Location': lpix, 'Source': limage}\n",
    "dataframe = pd.DataFrame(d)\n",
    "dataframe = dataframe.sort_values('Depth').reset_index(drop=True)\n",
    "dataframe.to_csv('pixel_depth_map.csv')\n",
    "dataframe"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "object_detection_tutorial.ipynb?workspaceId=ronnyvotel:python_inference::citc",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
